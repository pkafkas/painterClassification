{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92482505-282c-45a9-b977-97b6f1bd64a4",
   "metadata": {},
   "source": [
    "## 2. Classifier Training\n",
    "\n",
    "### 2.0 Introduction\n",
    "In this notebook we have the code nessecary in order to train three different classifiers, as well as displaing metrics and graphs about them. The data we use is created by the notebook \"1DataProcess\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0890668-6e52-498c-bef8-e8b5d7d5f223",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import asarray\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from skimage.filters import sobel\n",
    "from skimage.feature import hog\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import preprocessing\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "import time\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import plotly.figure_factory as ff\n",
    "import joblib\n",
    "import urllib.request\n",
    "import validators"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02be3957-276f-4d83-b7c9-d2349a027a6a",
   "metadata": {},
   "source": [
    "#### 2.1 Metric Functions\n",
    "\n",
    "In this section we define several functions used for the creation of different accuracy measuring graphs, lice roc curves, confusion matrix, presicion-recall etc. There is also at the end a method used for plotting the pca reduced feature matrix and for evaluating models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48d10c0-9cdc-4621-888d-17f99d0a9ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Roc Curve Display Function\n",
    "def createRocCurve(y_scores, y_onehot):\n",
    "\n",
    "    np.random.seed(0)\n",
    "\n",
    "    # Create an empty figure, and iteratively add new lines\n",
    "    # every time we compute a new class\n",
    "    fig = go.Figure()\n",
    "    fig.add_shape(\n",
    "        type='line', line=dict(dash='dash'),\n",
    "        x0=0, x1=1, y0=0, y1=1\n",
    "    )\n",
    "\n",
    "    for i in range(y_scores.shape[1]):\n",
    "        y_true = y_onehot.iloc[:, i]\n",
    "        y_score = y_scores[:, i]\n",
    "\n",
    "        fpr, tpr, _ = roc_curve(y_true, y_score)\n",
    "        auc_score = roc_auc_score(y_true, y_score)\n",
    "\n",
    "        name = f\"{y_onehot.columns[i]} (AUC={auc_score:.2f})\"\n",
    "        fig.add_trace(go.Scatter(x=fpr, y=tpr, name=name, mode='lines'))\n",
    "\n",
    "    fig.update_layout(\n",
    "        xaxis_title='False Positive Rate',\n",
    "        yaxis_title='True Positive Rate',\n",
    "        yaxis=dict(scaleanchor=\"x\", scaleratio=1),\n",
    "        xaxis=dict(constrain='domain'),\n",
    "        width=700, height=500\n",
    "    )\n",
    "    \n",
    "    return fig\n",
    "\n",
    "\n",
    "### Confusion Matric function\n",
    "def conf_m(cm, classes_dict):\n",
    "    z = cm\n",
    "\n",
    "    # invert z idx values\n",
    "    z = z[::-1]\n",
    "\n",
    "    #x = ['healthy', 'multiple diseases', 'rust', 'scab']\n",
    "    x = classes_dict\n",
    "    y =  x[::-1].copy() # invert idx values of x\n",
    "\n",
    "    # change each element of z to type string for annotations\n",
    "    z_text = [[str(y) for y in x] for x in z]\n",
    "\n",
    "    # set up figure \n",
    "    fig = ff.create_annotated_heatmap(z, x=x, y=y, annotation_text=z_text, colorscale='Viridis')\n",
    "\n",
    "    # add title\n",
    "    #fig.update_layout(title_text='<i><b>Confusion matrix</b></i>',\n",
    "    #                  #xaxis = dict(title='x'),\n",
    "    #                  #yaxis = dict(title='x')\n",
    "    #                 )\n",
    "\n",
    "    # add custom xaxis title\n",
    "    fig.add_annotation(dict(font=dict(color=\"black\",size=14),\n",
    "                            x=0.5,\n",
    "                            y=-0.15,\n",
    "                            showarrow=False,\n",
    "                            text=\"Predicted value\",\n",
    "                            xref=\"paper\",\n",
    "                            yref=\"paper\"))\n",
    "\n",
    "    # add custom yaxis title\n",
    "    fig.add_annotation(dict(font=dict(color=\"black\",size=14),\n",
    "                            x=-0.35,\n",
    "                            y=0.5,\n",
    "                            showarrow=False,\n",
    "                            text=\"Real value\",\n",
    "                            textangle=-90,\n",
    "                            xref=\"paper\",\n",
    "                            yref=\"paper\"))\n",
    "\n",
    "    # adjust margins to make room for yaxis title\n",
    "    fig.update_layout(\n",
    "        margin=dict(t=50, l=200),\n",
    "        width=700, height=500\n",
    "        )\n",
    "\n",
    "    # add colorbar\n",
    "    fig['data'][0]['showscale'] = True\n",
    "    #fig.show()\n",
    "    return fig\n",
    "\n",
    "\n",
    "# Precission REcall Curves\n",
    "def pr_rec_curve(y_onehot, y_scores):\n",
    "\n",
    "    np.random.seed(0)\n",
    "\n",
    "    # Create an empty figure, and iteratively add new lines\n",
    "    # every time we compute a new class\n",
    "    fig = go.Figure()\n",
    "    fig.add_shape(\n",
    "        type='line', line=dict(dash='dash'),\n",
    "        x0=0, x1=1, y0=1, y1=0\n",
    "    )\n",
    "\n",
    "    for i in range(y_scores.shape[1]):\n",
    "        y_true = y_onehot.iloc[:, i]\n",
    "        y_score = y_scores[:, i]\n",
    "\n",
    "        precision, recall, _ = precision_recall_curve(y_true, y_score)\n",
    "        auc_score = average_precision_score(y_true, y_score)\n",
    "\n",
    "        name = f\"{y_onehot.columns[i]} (AP={auc_score:.2f})\"\n",
    "        fig.add_trace(go.Scatter(x=recall, y=precision, name=name, mode='lines'))\n",
    "\n",
    "    fig.update_layout(\n",
    "        xaxis_title='Recall',\n",
    "        yaxis_title='Precision',\n",
    "        yaxis=dict(scaleanchor=\"x\", scaleratio=1),\n",
    "        xaxis=dict(constrain='domain'),\n",
    "        width=700, height=500\n",
    "    )\n",
    "    \n",
    "    return fig\n",
    "\n",
    "def plot_pca(feature_matrix_pca):\n",
    "    fig = px.scatter(feature_matrix_pca, x=\"pca_1\", y=\"pca_2\", color=\"painter\",\n",
    "                 hover_data=['painter'])\n",
    "    return fig\n",
    "\n",
    "### evaluate model function, prints accuracy and error\n",
    "def evaluate_model(model, test_labels):\n",
    "    start = time.time()\n",
    "    prediction = model.predict(X_test)\n",
    "    stop = time.time() \n",
    "    print(f\"Total inference time: {round(stop - start, 2)}s\")\n",
    "    print(f\"Inference time per example: {round((stop - start)/len(y_test),5)}s\")\n",
    "    print(f\"Test Set Accuracy : {accuracy_score(y_test, prediction) * 100} %\\n\\n\")\n",
    "    \n",
    "    return accuracy_score(y_test, prediction) * 100\n",
    "\n",
    "\n",
    "# This Function Calls Many of the above  ****** THis should be used for displaying ALL relevant graphs and ,metrics\n",
    "def display_metrics(model, X_test, y_test):\n",
    "    prediction = model.predict(X_test)\n",
    "    y_scores = model.predict_proba(X_test)\n",
    "    y_onehot = pd.get_dummies(y_test, columns=model.classes_)\n",
    "    y_onehot = pd.get_dummies(y_test, columns=model.classes_)\n",
    "    pred_score = round(accuracy_score(y_test, prediction) * 100.0, 2)\n",
    "    cm = confusion_matrix(y_test, prediction, labels=model.classes_)\n",
    "    \n",
    "    print(classification_report(y_test, prediction))\n",
    "    #print(type(classification_report(y_test, prediction)))\n",
    "\n",
    "    conf_matrix = conf_m(cm, list(model.classes_))\n",
    "    conf_matrix.show()\n",
    "    roc_figure = createRocCurve(y_scores, y_onehot)\n",
    "    roc_figure.show()\n",
    "    prec_recall = pr_rec_curve(y_onehot, y_scores)\n",
    "    prec_recall.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54297d8c-fb42-4aaf-8f69-fe7de573fed5",
   "metadata": {},
   "source": [
    "#### 2.2 Load Data & diplsay pca\n",
    "\n",
    "In this section we load the feature matrix dataset as it was created in notebook \"1DataProcess\". We display the pca reduced graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fdcd45c-8e9a-4971-a38c-0b25d32d95e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load Feature Matrix from .csv file\n",
    "feature_matrix = pd.read_csv('feature_matrix.csv')\n",
    "feature_matrix_pca = pd.read_csv('feature_matrix_pca.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31f55fb-9c4f-4778-af57-19bcd06f343f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the pca reduced image of the dataset:\n",
    "fig = px.scatter_3d(feature_matrix_pca, x='pca_1', y='pca_2', z='pca_3',\n",
    "              color='painter')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bab604d-a011-43c5-b3ad-a5450a533401",
   "metadata": {},
   "source": [
    "### 2.3 Data Splitting and Model Fitting\n",
    "In this segment we start creating/fitting and optimizing different classifiers on our data.\n",
    "\n",
    "1) Random Forest Classifier\n",
    "    \\- Random Forest Tuning\n",
    "    \\- Metrics Extraction\n",
    "2) SVM\n",
    "    \\- SVM Tuning\n",
    "    \\- Metrics Extraction\n",
    "3) KNN\n",
    "    \\- SVM Tuning\n",
    "    \\- Metrics Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfcbfa54-4a1f-4aa5-a2c1-cf6692ed82d5",
   "metadata": {},
   "source": [
    "### 2.4 Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3010c33b-1d9b-47df-b9af-630eb320a110",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_matrix = pd.read_csv('feature_matrix.csv')\n",
    "\n",
    "X = feature_matrix.drop(columns = 'painter')\n",
    "y = feature_matrix['painter']\n",
    "X = X.values\n",
    "y = y.values\n",
    "\n",
    "#le = preprocessing.LabelEncoder()\n",
    "#le.fit(y)\n",
    "#y = le.transform(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f89bb7-039f-4bb5-92cc-caf505e3b1b3",
   "metadata": {},
   "source": [
    "### 2.4.1 Basic Fit and Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e851e2-acef-4df8-a081-0c518b3d4185",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Get a basic estimation of the basic random forest performance on our dataset\n",
    "\n",
    "rfc = RandomForestClassifier()\n",
    "\n",
    "start = time.time()\n",
    "rfc.fit(X_train, y_train)\n",
    "stop = time.time()\n",
    "duration = round(stop - start, 2)\n",
    "print(f\"Total training time: {duration}s\")\n",
    "print(f\"Training time per example: {round(duration/len(y_train),5)}s\")\n",
    "\n",
    "start = time.time()\n",
    "prediction = rfc.predict(X_test)\n",
    "stop = time.time()\n",
    "print(f\"Total inference time: {round(stop - start, 2)}s\")\n",
    "print(f\"Inference time per example: {round((stop - start)/len(y_test),5)}s\")\n",
    "\n",
    "print(f\"Test Set Accuracy : {accuracy_score(y_test, prediction) * 100} %\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "364ebab9-d9d1-4ffd-bcc7-453346909fbc",
   "metadata": {},
   "source": [
    "### 2.4.2 RF Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386da481-9a7b-4026-b67c-92d7201e4acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create a new random forest classifier and this time perform tuning\n",
    "\n",
    "rfc = RandomForestClassifier()\n",
    "\n",
    "# Parameters used for seaerching in the tuning process\n",
    "n_estimators = [int(x) for x in np.linspace(start = 100, stop = 400, num = 3)]\n",
    "max_features = ['sqrt']\n",
    "max_depth = [int(x) for x in np.linspace(10, 100, num = 3)]\n",
    "max_depth.append(None)\n",
    "min_samples_split = [2, 5, 10]\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "bootstrap = [True, False]\n",
    "\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "print(random_grid)\n",
    "\n",
    "# Perform tuning\n",
    "rf_random = RandomizedSearchCV(estimator = rfc, scoring='accuracy', param_distributions = random_grid, n_iter = 30, cv = 5, \n",
    "                               verbose=2, random_state=42, n_jobs = 1)\n",
    "rf_random.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ab407c-90d8-4bf2-9fdb-9be244f5cc75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the best classifier\n",
    "\n",
    "rf_random.best_params_\n",
    "best_random = rf_random.best_estimator_\n",
    "print(rf_random.best_params_)\n",
    "\n",
    "# save the best classifier to a file for future use\n",
    "joblib.dump(best_random, 'best_rf_clf.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e065c5-f12e-43fa-b55e-3f1d6d558f3d",
   "metadata": {},
   "source": [
    "### 2.4.3 Compare and Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee465ab-85f0-46ca-a7ac-31ab931f23e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load best classifier and get performance metrics\n",
    "\n",
    "best_random = joblib.load('best_rf_clf.joblib')\n",
    "print(best_random.get_params())\n",
    "base_model = RandomForestClassifier()\n",
    "base_model.fit(X_train, y_train)\n",
    "\n",
    "# compare best model with the base model\n",
    "print('Optimized model accuracy: ')\n",
    "best_score = evaluate_model(best_random, X_test)\n",
    "print('Base model accuracy: ')\n",
    "base_score = evaluate_model(base_model, X_test)\n",
    "\n",
    "print('Accuracy gain: ')\n",
    "print(best_score - base_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9073b701-2fcd-4055-bb02-50ee7e7750f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display ALL performance related graphs (cm matrix, pr-rec curve, roc etc)\n",
    "display_metrics(best_random, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ca3384-8ad8-4ef1-ae8f-e9ef9abd68a5",
   "metadata": {},
   "source": [
    "### 2.5  SVM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c28ad781-370a-4557-973b-38e13c716fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_matrix = pd.read_csv('feature_matrix.csv')\n",
    "\n",
    "X = feature_matrix.drop(columns = 'painter')\n",
    "y = feature_matrix['painter']\n",
    "X = X.values\n",
    "y = y.values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b401693-e5aa-4bbb-93d2-c5914337b373",
   "metadata": {},
   "source": [
    "### 2.5.1 Basic Fit and Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa3dc418-ce11-4692-9c29-656dd5521506",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Get a basic estimation of the basic SVM performance on our dataset\n",
    "\n",
    "svc = SVC()\n",
    "\n",
    "start = time.time()\n",
    "rfc.fit(X_train, y_train)\n",
    "stop = time.time()\n",
    "duration = round(stop - start, 2)\n",
    "print(f\"Total training time: {duration}s\")\n",
    "print(f\"Training time per example: {round(duration/len(y_train),5)}s\")\n",
    "\n",
    "start = time.time()\n",
    "prediction = rfc.predict(X_test)\n",
    "stop = time.time()\n",
    "print(f\"Total inference time: {round(stop - start, 2)}s\")\n",
    "print(f\"Inference time per example: {round((stop - start)/len(y_test),5)}s\")\n",
    "\n",
    "print(f\"Test Set Accuracy : {accuracy_score(y_test, prediction) * 100} %\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f563126-7bd8-4b85-a6c6-ceeb27c04413",
   "metadata": {},
   "source": [
    "### 2.5.2 SVM Optimization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc70613-359a-4e35-a3d3-cf6ce5e35697",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create a new SVM classifier and this time perform tuning\n",
    "svc = SVC()\n",
    "\n",
    "rand_list = {'C': [1, 10, 100], \n",
    "              'gamma': [1, 0.1, 'scale'],\n",
    "              'kernel': ['rbf']}\n",
    "              \n",
    "rand_search = RandomizedSearchCV(svc, param_distributions = rand_list, n_iter = 9, cv = 3, scoring='accuracy', verbose = 10, n_jobs = 1) \n",
    "rand_search.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed7772ed-ea89-42cb-95c2-c7f965e8e8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the best classifier\n",
    "\n",
    "rand_search.best_params_\n",
    "best_svm = rand_search.best_estimator_\n",
    "print(rand_search.best_params_)\n",
    "\n",
    "# save the best classifier to a file for future use\n",
    "joblib.dump(best_svm, 'best_svm_clf.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "863094f5-ed02-4afa-a2b4-d35f3b3c6bab",
   "metadata": {},
   "source": [
    "### 2.5.3 Compare and Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a57c5b-3d68-4172-b65e-4746eec48509",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load best classifier\n",
    "\n",
    "\n",
    "#load best classifier and get performance metrics\n",
    "\n",
    "best_svm = joblib.load('best_svm_clf.joblib')\n",
    "print(best_svm.get_params())\n",
    "base_model = SVC()\n",
    "base_model.fit(X_train, y_train)\n",
    "\n",
    "# compare best model with the base model\n",
    "print('Optimized model accuracy: ')\n",
    "best_score = evaluate_model(best_svm, X_test)\n",
    "print('Base model accuracy: ')\n",
    "base_score = evaluate_model(base_model, X_test)\n",
    "\n",
    "print('Accuracy gain: ')\n",
    "print(best_score - base_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f84082-7b67-4a4d-be6b-6609c19ee7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display ALL performance related graphs (cm matrix, pr-rec curve, roc etc)\n",
    "display_metrics(best_svm, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d938d5-9d76-41b9-aed2-3e589fdc41c3",
   "metadata": {},
   "source": [
    "### 2.6 KNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f5c951-9896-42cd-b1ff-7ed3d5cb6193",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_matrix = pd.read_csv('feature_matrix.csv')\n",
    "\n",
    "X = feature_matrix.drop(columns = 'painter')\n",
    "y = feature_matrix['painter']\n",
    "X = X.values\n",
    "y = y.values\n",
    "\n",
    "x_train, x_test, y_train, y_test= train_test_split(X, y, test_size= 0.2, random_state=0)  \n",
    "   \n",
    "st_x= StandardScaler()    \n",
    "x_train= st_x.fit_transform(x_train)    \n",
    "x_test= st_x.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5c1ea0-b808-4d40-b190-49b824c5c3a8",
   "metadata": {},
   "source": [
    "### 2.6.1 Basic Fit and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855ce126-ea40-4cac-ade7-d085d799e124",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Get a basic estimation of the basic KNN Classifier performance on our dataset\n",
    "clf = KNeighborsClassifier()  \n",
    "\n",
    "start = time.time()\n",
    "clf.fit(X_train, y_train)\n",
    "stop = time.time()\n",
    "duration = round(stop - start, 2)\n",
    "print(f\"Total training time: {duration}s\")\n",
    "print(f\"Training time per example: {round(duration/len(y_train),5)}s\")\n",
    "\n",
    "start = time.time()\n",
    "prediction = clf.predict(X_test)\n",
    "stop = time.time()\n",
    "print(f\"Total inference time: {round(stop - start, 2)}s\")\n",
    "print(f\"Inference time per example: {round((stop - start)/len(y_test),5)}s\")\n",
    "\n",
    "print(f\"Test Set Accuracy : {accuracy_score(y_test, prediction) * 100} %\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe3ec3b-eb73-4c2a-bde8-e05380cd0838",
   "metadata": {},
   "source": [
    "### 2.6.2 KNN Optimization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8241750d-3158-4bbe-bac5-adce485e64e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create a new random forest classifier and this time perform tuning\n",
    "\n",
    "clf = KNeighborsClassifier()  \n",
    "\n",
    "#List Hyperparameters that we want to tune.\n",
    "leaf_size = list(range(1,50))\n",
    "n_neighbors = list(range(1,30))\n",
    "p=[1,2] #Convert to dictionary\n",
    "hyperparameters = dict(leaf_size=leaf_size, n_neighbors=n_neighbors, p=p)\n",
    "\n",
    "# Search for best\n",
    "random_search = RandomizedSearchCV(clf, hyperparameters, cv=10, verbose = 10, scoring='accuracy', n_jobs = 1 )#Fit the model\n",
    "random_search.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7544e4b4-ae94-4afa-b276-6dd59e13ebc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the best classifier\n",
    "\n",
    "random_search.best_params_\n",
    "best_knn = rand_search.best_estimator_\n",
    "print(rand_search.best_params_)\n",
    "\n",
    "# Save the best classifier to a file\n",
    "joblib.dump(best_knn, 'best_knn_clf.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc3698a3-d0ce-4e7a-ad56-c8a3994711c7",
   "metadata": {},
   "source": [
    "### 2.5.3 Compare and Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3073d6da-a975-4e12-ab59-e46cc1c8662f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load best classifier\n",
    "\n",
    "\n",
    "#load best classifier and get performance metrics\n",
    "\n",
    "best_knn = joblib.load('best_knn_clf.joblib')\n",
    "print(best_knn.get_params())\n",
    "base_model = KNeighborsClassifier()  \n",
    "base_model.fit(X_train, y_train)\n",
    "\n",
    "# compare best model with the base model\n",
    "print('Optimized model accuracy: ')\n",
    "best_score = evaluate_model(best_knn, X_test)\n",
    "print('Base model accuracy: ')\n",
    "base_score = evaluate_model(base_model, X_test)\n",
    "\n",
    "print('Accuracy gain: ')\n",
    "print(best_score - base_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc17a91-aea7-4860-bf96-06c1be8a35f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display ALL performance related graphs (cm matrix, pr-rec curve, roc etc)\n",
    "display_metrics(best_knn, X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
